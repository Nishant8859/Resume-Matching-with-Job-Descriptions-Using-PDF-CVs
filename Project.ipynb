{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers scikit-learn\n",
        "!pip install PyPDF2\n",
        "!pip install os-sys\n",
        "!pip install regex\n",
        "!pip install pdfplumber\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "DRuVfOdN3f6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import PyPDF2\n",
        "import pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def extract_information(text):\n",
        "    category = text.split('\\n', 1)[0].strip()\n",
        "\n",
        "    skills_match = re.search(r'Skills\\n(.*?)\\n', text, re.DOTALL)\n",
        "    if skills_match:\n",
        "        skills = skills_match.group(1).strip()\n",
        "    else:\n",
        "        skills = \"Not found\"\n",
        "\n",
        "    education_match = re.search(r'Education\\n(.*?)\\n', text, re.DOTALL)\n",
        "    if education_match:\n",
        "        education = education_match.group(1).strip()\n",
        "    else:\n",
        "        education = \"Not found\"\n",
        "\n",
        "    return {\n",
        "        \"Category\": category,\n",
        "        \"Skills\": skills,\n",
        "        \"Education\": education\n",
        "    }\n",
        "\n",
        "pdf_folder = \"data_resume/\"\n",
        "\n",
        "for filename in os.listdir(pdf_folder):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(pdf_folder, filename)\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        information = extract_information(text)\n",
        "\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"Category (Job role): {information['Category']}\")\n",
        "        print(f\"Skills: {information['Skills']}\")\n",
        "        print(f\"Education: {information['Education']}\")\n",
        "        print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "27Tl9fhq3jl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jacob-hugging-face/job-descriptions\")\n",
        "\n",
        "num_descriptions_to_fetch = 15\n",
        "descriptions = dataset[\"train\"][\"job_description\"][:num_descriptions_to_fetch]\n",
        "\n",
        "for idx, description in enumerate(descriptions, start=1):\n",
        "    print(f\"Job Description {idx}:\\n\")\n",
        "    print(description)\n",
        "    print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "4f7vr38nCY4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "job_descriptions = [dataset[\"train\"][\"job_description\"][i] for i in range(num_descriptions_to_fetch)]\n",
        "job_description_embeddings = []\n",
        "\n",
        "for description in job_descriptions:\n",
        "    tokens = tokenizer(description, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        output = model(**tokens)\n",
        "    embeddings = output.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "    job_description_embeddings.append(embeddings)\n",
        "\n",
        "cv_embeddings = []\n",
        "cv_information_list = []\n",
        "\n",
        "for filename in os.listdir(pdf_folder):\n",
        "    if filename.endswith(\".pdf\"):\n",
        "        pdf_path = os.path.join(pdf_folder, filename)\n",
        "        text = extract_text_from_pdf(pdf_path)\n",
        "        information = extract_information(text)\n",
        "        cv_information_list.append(information)\n",
        "        tokens = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            output = model(**tokens)\n",
        "        embeddings = output.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "        cv_embeddings.append(embeddings)\n",
        "\n",
        "job_description_embeddings = np.array(job_description_embeddings)\n",
        "cv_embeddings = np.array(cv_embeddings)"
      ],
      "metadata": {
        "id": "FgtG6Ae_E8ig"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_scores = cosine_similarity(job_description_embeddings, cv_embeddings)\n",
        "\n",
        "top_cv_indices = np.argsort(similarity_scores, axis=1)[:, ::-1]\n",
        "\n",
        "for i, description in enumerate(job_descriptions):\n",
        "    print(f\"Job Description {i + 1}:\\n\")\n",
        "    print(description)\n",
        "    print(\"\\nTop 5 CV Matches:\")\n",
        "    for j, cv_index in enumerate(top_cv_indices[i][:5]):\n",
        "        print(f\"CV {j + 1}: {cv_information_list[cv_index]['Category']} (Similarity Score: {similarity_scores[i][cv_index]:.4f})\")\n",
        "    print(\"=\" * 50 + \"\\n\")"
      ],
      "metadata": {
        "id": "hG4Z4FtXWvgl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}